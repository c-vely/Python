{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e648c77b",
   "metadata": {},
   "source": [
    "### 📌Q1. 가장 먼저 학습 데이터를 준비해보도록 하겠습니다. MNIST 데이터셋을 직접 Load해 봅시다. 데이터셋을 로드하고 DataLoader를 구현해보세요.\n",
    "\n",
    "* DataLoader를 이용해 MNIST 데이터셋을 로드해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "16e95b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac8b083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d2ffd2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7ace5f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fedefd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dset.MNIST (root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dset.MNIST (root=root, train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a6409438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data loader 구현\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e07129",
   "metadata": {},
   "source": [
    "### 📌Q2.데이터가 준비가 되었다면, 이제 그 데이터를 학습할 모델을 구현할 차례입니다. 그후 모델 안의 가중치를 초기화시켜보세요. 입력 데이터 형태에 맞도록 linear한 모델을 구성해보세요.\n",
    "\n",
    "* MNIST 입력의 크기는 28x28입니다.\n",
    "\n",
    "* 여기서 구현하는 linear 모델은 입력이 1차원이기 때문에 입력 차원을 맞춰보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "2b000e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "linear = torch.nn.Linear(784, 10, bias=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "10f3ce28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_11776\\2238913059.py:2: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  torch.nn.init.normal(linear.weight)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.1963,  0.6151, -0.4301,  ...,  0.1879, -0.8384, -0.2137],\n",
       "        [-0.0841,  1.1740, -1.1685,  ..., -0.0383,  0.1817,  0.1730],\n",
       "        [ 0.5375, -0.8526, -0.8004,  ..., -0.8893, -0.2328, -0.5297],\n",
       "        ...,\n",
       "        [ 1.4213, -0.6979,  0.2195,  ...,  1.0020, -0.4909,  0.2429],\n",
       "        [ 0.5657, -0.1137, -0.1228,  ..., -0.2837, -0.3430,  0.0146],\n",
       "        [-0.0469, -1.4833, -0.9512,  ..., -0.4798,  1.5152,  0.4757]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialization\n",
    "torch.nn.init.normal(linear.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1da53e",
   "metadata": {},
   "source": [
    "### 📌Q3. 위에서 구현한 모델을 학습시키기 위해서는 loss 함수와 opitmizer가 필요합니다. 아래 제시된 loss 함수와 optimizer를 구현해보세요. Loss 함수와 optimizer는 모델 안의 가중치를 업데이트 할 때 사용됩니다.\n",
    "\n",
    "* 옵티마이저는 SGD, Loss는 Cross Entropy Loss를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "10f651ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss fn - Cross Entropy Loss\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bcbd8ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer - SGD\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcc202a",
   "metadata": {},
   "source": [
    "### 📌Q4. 3번 문제까지 해결하셨다면, 이제 학습을 위한 준비는 거의 끝났다고 볼 수 있습니다. 위 구현 함수들을 이용해 학습 Loop를 구현해보세요.\n",
    "\n",
    "* 위에서 구현한 모델, optimzer, loss fn 등을 이용해 학습을 구현해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "763a5cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Step[600/600], Loss: 0.9098, Accuracy: 77.00%\n",
      "Epoch [2/15], Step[600/600], Loss: 0.8568, Accuracy: 82.00%\n",
      "Epoch [3/15], Step[600/600], Loss: 0.9429, Accuracy: 84.00%\n",
      "Epoch [4/15], Step[600/600], Loss: 0.4608, Accuracy: 91.00%\n",
      "Epoch [5/15], Step[600/600], Loss: 0.7316, Accuracy: 84.00%\n",
      "Epoch [6/15], Step[600/600], Loss: 0.5179, Accuracy: 89.00%\n",
      "Epoch [7/15], Step[600/600], Loss: 0.4712, Accuracy: 87.00%\n",
      "Epoch [8/15], Step[600/600], Loss: 0.3044, Accuracy: 92.00%\n",
      "Epoch [9/15], Step[600/600], Loss: 0.4762, Accuracy: 90.00%\n",
      "Epoch [10/15], Step[600/600], Loss: 0.5087, Accuracy: 90.00%\n",
      "Epoch [11/15], Step[600/600], Loss: 0.5068, Accuracy: 91.00%\n",
      "Epoch [12/15], Step[600/600], Loss: 0.3205, Accuracy: 90.00%\n",
      "Epoch [13/15], Step[600/600], Loss: 0.7154, Accuracy: 83.00%\n",
      "Epoch [14/15], Step[600/600], Loss: 0.5065, Accuracy: 90.00%\n",
      "Epoch [15/15], Step[600/600], Loss: 0.2553, Accuracy: 94.00%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    for i, (imgs, labels) in enumerate(train_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        imgs = imgs.view(-1, 28 * 28)\n",
    "        \n",
    "        outputs = linear(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        _,argmax = torch.max(outputs, 1)\n",
    "        accuracy = (labels == argmax).float().mean()\n",
    "        \n",
    "    if(i+1)%100 == 0:\n",
    "        print('Epoch [{}/{}], Step[{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch+1, training_epochs, i+1, len(train_loader), loss.item(), accuracy.item()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433e5765",
   "metadata": {},
   "source": [
    "### 📌Q5. 학습이 완료되면, 모델이 잘 동작하는지 테스트가 필요합니다. 데이터로드 파트에서 준비했던 테스트 데이터를 이용해 테스트를 진행해봅시다. 아래 테스트 코드를 완성해보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "84c0431a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy for 100 images: 92.00%\n",
      "Test accuracy for 200 images: 89.50%\n",
      "Test accuracy for 300 images: 90.33%\n",
      "Test accuracy for 400 images: 88.50%\n",
      "Test accuracy for 500 images: 87.80%\n",
      "Test accuracy for 600 images: 86.67%\n",
      "Test accuracy for 700 images: 87.14%\n",
      "Test accuracy for 800 images: 87.25%\n",
      "Test accuracy for 900 images: 87.56%\n",
      "Test accuracy for 1000 images: 87.00%\n",
      "Test accuracy for 1100 images: 87.00%\n",
      "Test accuracy for 1200 images: 86.58%\n",
      "Test accuracy for 1300 images: 86.08%\n",
      "Test accuracy for 1400 images: 86.14%\n",
      "Test accuracy for 1500 images: 85.80%\n",
      "Test accuracy for 1600 images: 86.00%\n",
      "Test accuracy for 1700 images: 86.06%\n",
      "Test accuracy for 1800 images: 86.00%\n",
      "Test accuracy for 1900 images: 86.16%\n",
      "Test accuracy for 2000 images: 85.90%\n",
      "Test accuracy for 2100 images: 85.71%\n",
      "Test accuracy for 2200 images: 85.77%\n",
      "Test accuracy for 2300 images: 86.00%\n",
      "Test accuracy for 2400 images: 86.12%\n",
      "Test accuracy for 2500 images: 86.16%\n",
      "Test accuracy for 2600 images: 86.12%\n",
      "Test accuracy for 2700 images: 86.04%\n",
      "Test accuracy for 2800 images: 86.18%\n",
      "Test accuracy for 2900 images: 86.45%\n",
      "Test accuracy for 3000 images: 86.47%\n",
      "Test accuracy for 3100 images: 86.61%\n",
      "Test accuracy for 3200 images: 86.59%\n",
      "Test accuracy for 3300 images: 86.79%\n",
      "Test accuracy for 3400 images: 86.85%\n",
      "Test accuracy for 3500 images: 86.89%\n",
      "Test accuracy for 3600 images: 86.72%\n",
      "Test accuracy for 3700 images: 86.86%\n",
      "Test accuracy for 3800 images: 86.79%\n",
      "Test accuracy for 3900 images: 86.62%\n",
      "Test accuracy for 4000 images: 86.52%\n",
      "Test accuracy for 4100 images: 86.54%\n",
      "Test accuracy for 4200 images: 86.57%\n",
      "Test accuracy for 4300 images: 86.44%\n",
      "Test accuracy for 4400 images: 86.43%\n",
      "Test accuracy for 4500 images: 86.36%\n",
      "Test accuracy for 4600 images: 86.35%\n",
      "Test accuracy for 4700 images: 86.47%\n",
      "Test accuracy for 4800 images: 86.52%\n",
      "Test accuracy for 4900 images: 86.41%\n",
      "Test accuracy for 5000 images: 86.42%\n",
      "Test accuracy for 5100 images: 86.49%\n",
      "Test accuracy for 5200 images: 86.62%\n",
      "Test accuracy for 5300 images: 86.77%\n",
      "Test accuracy for 5400 images: 86.96%\n",
      "Test accuracy for 5500 images: 87.13%\n",
      "Test accuracy for 5600 images: 87.29%\n",
      "Test accuracy for 5700 images: 87.32%\n",
      "Test accuracy for 5800 images: 87.36%\n",
      "Test accuracy for 5900 images: 87.42%\n",
      "Test accuracy for 6000 images: 87.42%\n",
      "Test accuracy for 6100 images: 87.38%\n",
      "Test accuracy for 6200 images: 87.42%\n",
      "Test accuracy for 6300 images: 87.62%\n",
      "Test accuracy for 6400 images: 87.75%\n",
      "Test accuracy for 6500 images: 87.82%\n",
      "Test accuracy for 6600 images: 87.77%\n",
      "Test accuracy for 6700 images: 87.82%\n",
      "Test accuracy for 6800 images: 87.81%\n",
      "Test accuracy for 6900 images: 87.94%\n",
      "Test accuracy for 7000 images: 88.03%\n",
      "Test accuracy for 7100 images: 88.18%\n",
      "Test accuracy for 7200 images: 88.26%\n",
      "Test accuracy for 7300 images: 88.34%\n",
      "Test accuracy for 7400 images: 88.47%\n",
      "Test accuracy for 7500 images: 88.43%\n",
      "Test accuracy for 7600 images: 88.50%\n",
      "Test accuracy for 7700 images: 88.58%\n",
      "Test accuracy for 7800 images: 88.67%\n",
      "Test accuracy for 7900 images: 88.58%\n",
      "Test accuracy for 8000 images: 88.59%\n",
      "Test accuracy for 8100 images: 88.59%\n",
      "Test accuracy for 8200 images: 88.71%\n",
      "Test accuracy for 8300 images: 88.75%\n",
      "Test accuracy for 8400 images: 88.81%\n",
      "Test accuracy for 8500 images: 88.85%\n",
      "Test accuracy for 8600 images: 88.93%\n",
      "Test accuracy for 8700 images: 89.05%\n",
      "Test accuracy for 8800 images: 89.17%\n",
      "Test accuracy for 8900 images: 89.28%\n",
      "Test accuracy for 9000 images: 89.38%\n",
      "Test accuracy for 9100 images: 89.36%\n",
      "Test accuracy for 9200 images: 89.46%\n",
      "Test accuracy for 9300 images: 89.51%\n",
      "Test accuracy for 9400 images: 89.61%\n",
      "Test accuracy for 9500 images: 89.62%\n",
      "Test accuracy for 9600 images: 89.68%\n",
      "Test accuracy for 9700 images: 89.63%\n",
      "Test accuracy for 9800 images: 89.49%\n",
      "Test accuracy for 9900 images: 89.39%\n",
      "Test accuracy for 10000 images: 89.35%\n"
     ]
    }
   ],
   "source": [
    "linear.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for i, (imgs, labels) in enumerate(test_loader):\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        imgs = imgs.view(-1, 28*28)\n",
    "        \n",
    "        outputs = linear(imgs)\n",
    "        \n",
    "        _, argmax = torch.max(outputs, 1)\n",
    "        total += imgs.size(0)\n",
    "        correct += (labels == argmax).sum().item()\n",
    "        \n",
    "        print('Test accuracy for {} images: {:.2f}%'.format(total, correct / total*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
